# -*- coding: utf-8 -*-
"""Welcome To Colaboratory

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

import tensorflow as tf
import numpy as np

from tensorflow import keras
from tensorflow.keras import layers

print(tf.__version__)

pip install git+https://github.com/tensorflow/docs

import pandas as pd
dataset=pd.read_csv("data.csv")
dataset

dataset=pd.get_dummies(dataset,columns=['label'])
dataset.head()

train_data=dataset.sample(frac=0.8,random_state=8)
test_data=dataset.drop(train_data.index)
train_data

test_data

train_labels = pd.DataFrame([train_data.pop(x) for x in ['label_Red', 'label_Green', 'label_Blue', 'label_Yellow', 'label_Orange', 'label_Pink', 'label_Purple', 'label_Brown', 'label_Grey', 'label_Black', 'label_White']]).T
train_labels

test_labels=pd.DataFrame([test_data.pop(x) for x in ['label_Red', 'label_Green', 'label_Blue', 'label_Yellow', 'label_Orange', 'label_Pink', 'label_Purple', 'label_Brown', 'label_Grey', 'label_Black', 'label_White']]).T
test_labels

test_data

model=keras.Sequential([
    layers.Dense(3,activation='relu',input_shape=[len(train_data.keys())]),
    layers.Dense(22,activation='relu'),
    layers.Dense(22,activation='relu'),
    layers.Dense(11)
])
optimizer = keras.optimizers.Adam(learning_rate=0.002)
loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=True)

model.compile(loss=loss_function,
                optimizer=optimizer,
                metrics=['accuracy'])

model.summary()

import tensorflow_docs as tfdocs
import tensorflow_docs.plots
import tensorflow_docs.modeling
np.shape(train_data)

history = model.fit(x=train_data, y=train_labels, 
                    validation_split=0.2, 
                    epochs=5001, 
                    batch_size=2048, 
                    verbose=0,
                    callbacks=[tfdocs.modeling.EpochDots()], 
                    shuffle=True)

import matplotlib.pyplot as plt
plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)
plotter.plot({'Basic': history}, metric = "accuracy")
plt.ylim([0, 1])
plt.ylabel('accuracy [Color]')

plotter.plot({'Basic': history}, metric = "loss")
plt.ylim([0, 1])
plt.ylabel('loss [Color]')

test_predictions = model.predict(test_data)
print("shape is {}".format(test_predictions.shape))  
test_predictions

#Selecting Class with highest confidence
predicted_encoded_test_labels = np.argmax(test_predictions, axis=1) #Returns the indices of the maximum values along each row(axis=1)
#Converting numpy array to pandas dataframe
predicted_encoded_test_labels = pd.DataFrame(predicted_encoded_test_labels, columns=['Predicted Labels'])
predicted_encoded_test_labels

#Converting One-Hot Encoded Actual Test set labels into Label Encoding format
actual_encoded_test_labels = np.argmax(test_labels.to_numpy(), axis=1) 
#Converting numpy array to pandas dataframe
actual_encoded_test_labels = pd.DataFrame(actual_encoded_test_labels, columns=['Actual Labels'])
actual_encoded_test_labels